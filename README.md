# Compilers, Interpreters & Language Working



ğŸ”¹ 1. Compiler vs Interpreter :-

Compiler: Translates entire program into machine code (faster execution).

Ex: C, C++ (compiled â†’ binary â†’ run).


Interpreter: Executes code line-by-line (slower, flexible).

Ex: Python, JavaScript.



---

ğŸ”¹ 2. How Python Works :-

1. Python source code (.py) â†’ Interpreter


2. Code is first compiled into bytecode (.pyc)


3. Bytecode is executed by the Python Virtual Machine (PVM)


4. Optional: JIT (Just-In-Time) compilers like PyPy speed up execution.



---

ğŸ”¹ 3. How Other Languages Work :-

C / C++

Source code â†’ Compiler â†’ Machine code (direct execution).


Java

Source code â†’ Compiler â†’ Bytecode (.class) â†’ JVM (interprets / JIT compiles).


JavaScript

Code â†’ JS Engine (e.g., V8) â†’ Parser + Interpreter + JIT â†’ Machine code.


Go / Rust

Source code â†’ Compiler â†’ Binary â†’ Run (like C).



---

ğŸ”¹ 4. Six Phases of Compilation (Universal) :- 

1. Lexical Analysis (Scanner) :-

Breaks code into tokens.

Ex: int x = 5; â†’ int, x, =, 5, ;



2. Syntax Analysis (Parser) :-

Checks grammar via parse tree/AST.

Ex: Verifies assignment statement.



3. Semantic Analysis :-

Checks meaning (type checking, scope rules).

Ex: Canâ€™t add string to int.



4. Intermediate Code Generation (IR) :-

Converts AST â†’ Intermediate Representation (portable).



5. Optimization :-

Improves IR (remove redundancies, loop optimizations).



6. Code Generation :-

IR â†’ Target Machine Code (assembly/binary).




(Additional Phase: Symbol Table Management + Error Handling throughout)


---

ğŸ”¹ 5. Mapping Phases in Languages :-

C / C++ â†’ All 6 phases â†’ Machine Code.

Java â†’ All 6 phases â†’ Bytecode â†’ JVM interprets/JIT compiles.

Python â†’ Mini-compiler (phases 1â€“4) â†’ Bytecode â†’ PVM interprets.

JavaScript â†’ Parser + Interpreter + JIT â†’ Optimized machine code.



---

ğŸ”¹ 6. Key Takeaways :-

Compiled langs = Faster, optimized binaries.

Interpreted langs = Flexible, slower, but portable.

Modern trend: Hybrid (Bytecode + VM + JIT) â†’ Best of both worlds.



---




# From High-Level Language to Executable + Platform Dependence



ğŸ”¹ 1. Journey of Code (HLL â†’ Executable)

1. High-Level Language (HLL)

Human-readable code (Python, C, Java).



2. Preprocessing (C/C++ only)

Handles macros, header files, directives (#include, #define).



3. Compilation

HLL â†’ Assembly/Intermediate Code

Syntax + semantic checks done here.



4. Assembly

Converts to machine instructions (object code).



5. Linking

Combines multiple object files + libraries into a single executable.



6. Loading & Execution

OS loads executable into memory and CPU runs it.





---

ğŸ”¹ 2. Execution Flow in Different Languages

C/C++
HLL â†’ Compiler â†’ Object Code â†’ Linker â†’ Executable (Platform Dependent)

Java
HLL (.java) â†’ Compiler â†’ Bytecode (.class) â†’ JVM â†’ Machine Code (Platform Independent via JVM)

Python
HLL (.py) â†’ Interpreter â†’ Bytecode (.pyc) â†’ Python Virtual Machine (PVM) â†’ Execution

.NET Languages (C#, VB.NET)
HLL â†’ Compiler â†’ CIL (Common Intermediate Language) â†’ CLR (Common Language Runtime) â†’ Execution



---

ğŸ”¹ 3. Platform Dependent vs Platform Independent

ğŸ“ Platform Dependent

Code runs only on the system/architecture it was compiled for.

Ex: C/C++ â†’ compiled into machine code specific to Windows/Linux/Mac.

Requires recompilation for each OS.


ğŸ“ Platform Independent

Code runs on any platform with a supporting VM/runtime.

Ex: Java (JVM), Python (PVM), .NET (CLR).

HLL â†’ Intermediate Code â†’ Executed on VM (portable).



---

ğŸ”¹ 4. Key Idea

Native compilation â†’ fast, but platform dependent.

VM/Bytecode â†’ portable, but slightly slower.

Modern JIT compilers (Java HotSpot, PyPy, V8 for JS) bridge the gap: portability + speed.



---

âš¡ Quick Mnemonic:
ğŸ‘‰ â€œWrite Once, Run Anywhereâ€ = Platform Independent (Java, Python).
ğŸ‘‰ â€œWrite Once, Compile Everywhereâ€ = Platform Dependent (C/C++).



---





# AI, Data Science, and Acceleration 



ğŸ”¹ Data Science Foundations

Data Science â†’ Extracting insights from structured/unstructured data.

Pandas â†’ Series (1D) + DataFrames (2D) for data manipulation.

NumPy â†’ Arrays, linear algebra backbone.

Scikit-learn (sklearn) â†’ Classical ML algorithms (SVM, Random Forest, Regression).

TensorFlow / PyTorch â†’ Deep Learning frameworks for neural networks.



---

ğŸ”¹ Math Backbone

Matrix / Linear Algebra â†’ Foundation of ML/DL (vector spaces, transformations).

Dimensions â†’

Scalar = 0D (single value)

Vector = 1D (array)

Matrix = 2D

Tensor = n-D (generalization).




---

ğŸ”¹ AI & Advanced Concepts

Deep Learning â†’ Neural networks with multiple hidden layers.

RAG (Retrieval Augmented Generation) â†’ Combines LLMs with external knowledge bases.

Graph RAG â†’ Extends RAG using graph databases for better context + relationships.

Agents â†’ Autonomous AI units (e.g., LangChain agents) that plan, reason, and act.

MCP in AI (Multi-Component Pipeline) â†’ Breaks AI workflows into stages (data prep â†’ training â†’ inference).

VPP in AI (Vector Packet Processing) â†’ High-performance networking for AI workloads (fast data movement).



---

ğŸ”¹ System / Hardware Acceleration

Path (SR-IOV, DPDK, eBPF)

SR-IOV â†’ Direct NIC access to VM (faster I/O).

DPDK â†’ User-space packet processing (high speed).

eBPF â†’ Kernel-level programmable hooks (efficient packet filtering).


Offload to Workload â†’ Push heavy compute (encryption, ML ops) to accelerators (GPUs, TPUs, SmartNICs).

Cryptoaccelerators â†’ Hardware for cryptography (AES, RSA, SSL offload).

PCIE â†’ High-speed bus connecting CPU â†” GPU/accelerators.



---

ğŸ”¹ Relation Flow

1. Data Science stack: NumPy â†’ Pandas â†’ Scikit-learn â†’ TensorFlow.


2. Math Core: Linear algebra + tensors = foundation of ML/DL.


3. Advanced AI: RAG/Graph RAG + Agents enhance LLMs.


4. Pipelines: MCP = modular AI workflow, VPP = high-speed data handling.


5. System Optimization: SR-IOV, DPDK, eBPF for networked AI workloads.


6. Acceleration: Offload ML tasks to GPUs/TPUs over PCIe; cryptoaccelerators secure workloads.




---





# Cloud Computing (9/09/25) 


ğŸŒ Exposing Nginx on AWS + Securing with Letâ€™s Encrypt

1. Setup AWS VM (EC2 Instance) :-

Launch an EC2 Instance (Ubuntu/Debian/RedHat).

Assign a Public IP (or Elastic IP for permanence).

Security Group: Open ports â†’ 22 (SSH), 80 (HTTP), 443 (HTTPS).



---

2. Install Nginx :-

sudo apt update
sudo apt install nginx -y

Start service:


sudo systemctl start nginx
sudo systemctl enable nginx

Verify: Visit http://<Public-IP> â†’ Default Nginx page should appear.



---

3. Expose Nginx on Public IP :-

AWS automatically maps Public IP â†’ Private IP.

Ensure UFW / iptables allows 80, 443:


sudo ufw allow 'Nginx Full'

Test: Access via browser â†’ http://<EC2-Public-IP>.



---

4. Map Domain Name (Optional, Recommended) :-

Buy/register a domain (Route53, GoDaddy, etc.).

Create an A Record â†’ Point domain â†’ EC2 Public IP.

Test: http://yourdomain.com.



---

5. Install Certbot (Letâ€™s Encrypt):- 

Install:


sudo apt install certbot python3-certbot-nginx -y

Obtain SSL Certificate:


sudo certbot --nginx -d yourdomain.com -d www.yourdomain.com

Certbot will:

Edit Nginx config.

Redirect HTTP â†’ HTTPS.

Install certificates in /etc/letsencrypt/.




---

6. Auto-Renew SSL :- 

Certificates valid 90 days.

Enable cron renewal:


sudo systemctl enable certbot.timer
sudo systemctl start certbot.timer

Test renewal:


sudo certbot renew --dry-run


---

7. Final Verification :- 

Access site via:

https://yourdomain.com â†’ Should show ğŸ”’ Secure Padlock.


Nginx config (/etc/nginx/sites-available/default) should auto-contain HTTPS blocks:


server {
    listen 443 ssl;
    server_name yourdomain.com www.yourdomain.com;
    ssl_certificate /etc/letsencrypt/live/yourdomain.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/yourdomain.com/privkey.pem;
}


---


Exposing Nginx using K3s on AWS :-


---

1. Install K3s (Single Node Master on AWS VM)

curl -sfL https://get.k3s.io | sh -

Verify:

sudo kubectl get nodes


---

2. Deploy Nginx on K3s :-

sudo kubectl create deployment nginx --image=nginx

Check pods:

sudo kubectl get pods


---

3. Expose Nginx Service :-

Option A: NodePort (Basic Exposure)

sudo kubectl expose deployment nginx --type=NodePort --port=80
sudo kubectl get svc

Note the NodePort (e.g., 30080).

Access via:

http://<AWS-Public-IP>:<NodePort>



---


# Multiple Approaches for hosting website in AWS

Apache (Service) â†’ Docker â†’ Minikube â†’ Kubernetes â†’ AWS private cloud hosting.
